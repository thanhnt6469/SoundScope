# Model settings
LLM_MODEL: "llama-3.1-8b-instant"
TEMPERATURE: 0.3
MAX_TOKENS: 512
TOP_P: 0.5
STOP: null
STREAM: false